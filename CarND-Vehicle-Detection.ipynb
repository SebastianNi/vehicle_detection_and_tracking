{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#%matplotlib inline\n",
    "\n",
    "output_folder = './output_images/'\n",
    "non_vehicle_folder = './data/non-vehicles/'\n",
    "vehicle_folder = './data/vehicles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def saveImage(img, file_name=None, file_name_extension=None, isRGB=False):\n",
    "    if file_name!=None:\n",
    "        # Slice out the filename from the path\n",
    "        new_file_name = file_name[max(file_name.rfind('\\\\'), file_name.rfind('/')) + 1:file_name.rfind('.')]\n",
    "        # If the filename should be extended, add the extension\n",
    "        if file_name_extension!=None:\n",
    "            new_file_name += file_name_extension\n",
    "        # Save the image to a file\n",
    "        if isRGB:\n",
    "            cv2.imwrite(output_folder + new_file_name + '.png', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "        else:\n",
    "            cv2.imwrite(output_folder + new_file_name + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Returns some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=False, transform_sqrt=False):\n",
    "    if vis == True:\n",
    "        # Use skimage.hog() to get both features and a visualization\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=transform_sqrt,\n",
    "                                  visualise=True, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:\n",
    "        # Use skimage.hog() to get features only\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=transform_sqrt,\n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Compute color histogram features from a BGR image\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a feature list of the color channels\n",
    "def color_hist(img, channel_list_str, nbins, bins_range, file_name=None):\n",
    "    \n",
    "    if (len(img.shape)==2) or (img.shape[2]==1):\n",
    "        channel1_hist = np.histogram(img, bins=nbins, range=bins_range)\n",
    "    else:\n",
    "        # Compute the histogram of the color channels separately\n",
    "        channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "        channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "        channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    if ((file_name!=None) & (len(img.shape)==3)):\n",
    "        # Store an image of the histogram\n",
    "        \n",
    "        # Generate bin centers\n",
    "        bin_edges = channel1_hist[1]\n",
    "        bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges)-1]) / 2\n",
    "        \n",
    "        # Plot a figure with all three bar charts\n",
    "        fig = plt.figure(figsize=(21,3))\n",
    "        plt.subplot(131)\n",
    "        plt.bar(bin_centers, channel1_hist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title(channel_list_str[0] + ' Channel Histogram')\n",
    "        plt.subplot(132)\n",
    "        plt.bar(bin_centers, channel2_hist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title(channel_list_str[1] + ' Channel Histogram')\n",
    "        plt.subplot(133)\n",
    "        plt.bar(bin_centers, channel3_hist[0])\n",
    "        plt.xlim(0, 256)\n",
    "        plt.title(channel_list_str[2] + ' Channel Histogram')\n",
    "        \n",
    "        # Slice out the filename from the path\n",
    "        new_file_name = file_name[max(file_name.rfind('\\\\'), file_name.rfind('/')) + 1:file_name.rfind('.')]\n",
    "        # Add the filename extension\n",
    "        new_file_name += ('_01_' + channel_list_str[0][0] + channel_list_str[1][0] + channel_list_str[2][0] + '_hist')\n",
    "        \n",
    "        # Store the image\n",
    "        fig.savefig(output_folder + new_file_name + '.png')\n",
    "    \n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    if (len(img.shape)==2) or (img.shape[2]==1):\n",
    "        hist_features = channel1_hist[0]\n",
    "    else:\n",
    "        hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_features(img, spatial_size, hist_bins, hist_range, channel_list_str, file_name=None):\n",
    "            \n",
    "    # Apply bin_spatial() to get spatial color features\n",
    "    spatial_features = bin_spatial(img, size=spatial_size)\n",
    "    # Apply color_hist() also with a color space option now\n",
    "    hist_features = color_hist(img, channel_list_str=channel_list_str, nbins=hist_bins,\n",
    "                               bins_range=hist_range, file_name=file_name)\n",
    "    \n",
    "    # Return feature vector\n",
    "    return np.concatenate((spatial_features, hist_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot3d(pixels, colors_rgb, axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scaleData(X):\n",
    "    # Create an array stack of feature vectors\n",
    "    #X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    return scaled_X, X_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Properties for color feature extraction\n",
    "#color_space = 'BGR'\n",
    "#color_space = 'HSV'\n",
    "#color_space = 'LUV'\n",
    "color_space = 'HLS'\n",
    "#color_space = 'YUV'\n",
    "#color_space = 'YCrCb'\n",
    "spatial_size=(16, 16)\n",
    "hist_bins=256\n",
    "hist_range=(0, 256)\n",
    "\n",
    "# Properties for hog feature extraction\n",
    "color_channels = [0,1,2,3] # 0,1,2 for the color channel of the color space, 3 for gray scaled image\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "transform_sqrt = False\n",
    "\n",
    "store_image_size = (720,720)\n",
    "\n",
    "def generateImageFeatures(img, file_name=None, display_number_of_features=False,\n",
    "                          include_color_features=True, include_hog_features=True):\n",
    "    \n",
    "    # Convert image to new color space (if specified)\n",
    "    if color_space != 'BGR':\n",
    "        if color_space == 'RGB':\n",
    "            channel_list_str = ['Red', 'Green', 'Blue']\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        elif color_space == 'HSV':\n",
    "            channel_list_str = ['Hue', 'Saturation', 'Value']\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            channel_list_str = ['L', 'U', 'V']\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            channel_list_str = ['Hue', 'Lightness', 'Saturation']\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            channel_list_str = ['Y', 'U', 'V']\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            channel_list_str = ['Y', 'Cr', 'Cb']\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        else:\n",
    "            print('WARNING: Color space is not defined in the extract_feature function!')\n",
    "    else:\n",
    "        channel_list_str = ['Blue', 'Green', 'Red']\n",
    "        feature_image = np.copy(img)\n",
    "    \n",
    "    # Get a list of color features\n",
    "    color_features = extract_features(feature_image, spatial_size=spatial_size, hist_bins=hist_bins, hist_range=hist_range,\n",
    "                                      channel_list_str=channel_list_str, file_name=file_name)\n",
    "    \n",
    "    hog_features = []\n",
    "    for channel in color_channels:\n",
    "        # Create an image of one color\n",
    "        if channel==3:\n",
    "            hog_img = cv2.cvtColor(feature_image, cv2.COLOR_BGR2GRAY)\n",
    "            channel_list_str.append('Gray')\n",
    "        else:\n",
    "            hog_img = feature_image[:,:,channel]\n",
    "        \n",
    "        if file_name!=None:\n",
    "            h_features, hog_image = get_hog_features(hog_img, orient=orient, pix_per_cell=pix_per_cell,\n",
    "                                                        cell_per_block=cell_per_block, vis=True, feature_vec=False,\n",
    "                                                        transform_sqrt=transform_sqrt)\n",
    "            hog_image = cv2.resize(hog_image, store_image_size, interpolation=cv2.INTER_NEAREST)\n",
    "            saveImage(hog_image, file_name=file_name, file_name_extension='_03_hog_' + channel_list_str[channel], isRGB=False)\n",
    "        else:\n",
    "            h_features = get_hog_features(hog_img, orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block,\n",
    "                                            vis=False, feature_vec=False, transform_sqrt=transform_sqrt)\n",
    "        hog_features = np.concatenate((hog_features, h_features.ravel()))\n",
    "        \n",
    "    # store the images to use them in the writeup\n",
    "    if file_name!=None:\n",
    "        resized_image = cv2.resize(img, store_image_size, interpolation=cv2.INTER_NEAREST)\n",
    "        saveImage(resized_image, file_name=file_name, file_name_extension=None, isRGB=False)\n",
    "        for channel in color_channels:\n",
    "            if channel==3:\n",
    "                store_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                store_image = resized_image[:,:,channel]\n",
    "            saveImage(store_image, file_name=file_name,\n",
    "                        file_name_extension='_02_color_channel_' + channel_list_str[channel], isRGB=False)\n",
    "    \n",
    "    # Deside what to return\n",
    "    if (include_color_features==True) & (include_hog_features==True):\n",
    "        # Concatinate the color and hog features\n",
    "        image_features = np.concatenate((color_features, hog_features))\n",
    "    elif include_color_features==True:\n",
    "        # Just return color features\n",
    "        image_features = color_features\n",
    "    elif include_hog_features==True:\n",
    "        # Just return hog features\n",
    "        image_features = hog_features\n",
    "    else:\n",
    "        # Senseless state! Return an empty list!\n",
    "        image_features = []\n",
    "    \n",
    "    if display_number_of_features:\n",
    "        print('Number of extracted color features: ' + str(len(color_features)))\n",
    "        print('Number of extracted hog features: ' + str(len(hog_features)))\n",
    "        print('Total Number of extracted data features: ' + str(len(image_features)))\n",
    "        \n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_shape': (64, 64, 3), 'n_cars': 8822, 'n_notcars': 9003, 'data_type': dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "# Read the vehicle and non-vehicle images\n",
    "vehicle_images = glob.glob(vehicle_folder + '/*/*.png')\n",
    "non_vehicle_images = glob.glob(non_vehicle_folder + '/*/*.png')\n",
    "\n",
    "# Display basic information about the data\n",
    "data_info = data_look(vehicle_images, non_vehicle_images)\n",
    "print(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 17825\n",
      "Total number of features: 8592\n"
     ]
    }
   ],
   "source": [
    "# Gerarate the training and testing data\n",
    "include_color_features=True\n",
    "include_hog_features=True\n",
    "\n",
    "image_features_list = []\n",
    "for fname in np.concatenate((vehicle_images, non_vehicle_images)):\n",
    "    img = cv2.imread(fname)\n",
    "    image_features = generateImageFeatures(img, file_name=None, display_number_of_features=False,\n",
    "                                           include_color_features=include_color_features,\n",
    "                                           include_hog_features=include_hog_features)\n",
    "    image_features_list.append(image_features)\n",
    "\n",
    "# Scale the data and get the scaler to scale the other images\n",
    "X, X_scaler = scaleData(image_features_list)\n",
    "y = np.hstack((np.ones(len(vehicle_images)), np.zeros(len(non_vehicle_images))))\n",
    "\n",
    "print('Total number of examples: ' + str(len(X)))\n",
    "print('Total number of features: ' + str(len(X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [0.1, 0.3, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Try several parameter values for C\n",
    "parameters = {'C':[0.1, 0.3, 1]}\n",
    "svc = LinearSVC(random_state=42)\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter for C is: 0.1\n"
     ]
    }
   ],
   "source": [
    "print('Best parameter for C is: ' + str(clf.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of the LinearSVC =  1.0\n",
      "Test accuracy of the LinearSVC =  0.993548387097\n"
     ]
    }
   ],
   "source": [
    "# Use a linear SVC\n",
    "svc = LinearSVC(C=clf.best_params_['C'], random_state=42)\n",
    "# Train the SVC\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "print('Training accuracy of the LinearSVC = ', svc.score(X_train, y_train))\n",
    "print('Test accuracy of the LinearSVC = ', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make a prediction for a single image\n",
    "def predictImage(img, file_name=None):\n",
    "    # Since the training data consists of 64x64 images, resize the image to the same format\n",
    "    if img.shape[0:2]!=(64,64):\n",
    "        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_NEAREST)\n",
    "    # Generate the features for the image\n",
    "    image_features = generateImageFeatures(img, file_name=file_name, display_number_of_features=False,\n",
    "                                           include_color_features=include_color_features,\n",
    "                                           include_hog_features=include_hog_features)\n",
    "    # Scale the features\n",
    "    image_features = image_features.reshape(1, -1)\n",
    "    image_features = X_scaler.transform(image_features)\n",
    "    # Return the prediction\n",
    "    return svc.predict(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here is your draw_boxes function from the previous exercise\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched\n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step)\n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step)\n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "heatmap_threshold = 5\n",
    "\n",
    "global_counter = 0\n",
    "round_buffer = [[],[],[],[],[]]\n",
    "round_buffer_size = len(round_buffer)\n",
    "\n",
    "# Run through the test images and find the lane lines\n",
    "def detectVehicles(img, file_name=None):\n",
    "    # Convert to BGR because CV2 uses BRG as default\n",
    "    local_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    search_area = [(400,480),(400,526),(400,558),(400,656)]\n",
    "    dimensions = [64,96,126,256]\n",
    "    for i in range(len(dimensions)):\n",
    "        d = dimensions[i]\n",
    "        ystart = search_area[i][0]\n",
    "        ystop = search_area[i][1]\n",
    "        windows = slide_window(local_img, x_start_stop=[None, None], y_start_stop=[ystart, ystop],\n",
    "                                   xy_window=(d, d), xy_overlap=(0.75, 0.75))\n",
    "        \n",
    "        # Iterate over all windows in the list\n",
    "        for window in windows:\n",
    "            sliced_img = local_img[window[0][1]:window[1][1], window[0][0]:window[1][0]]\n",
    "            prediction = predictImage(sliced_img, file_name=None)\n",
    "            # If positive (prediction == 1) then save the window\n",
    "            if prediction == 1:\n",
    "                on_windows.append(window)\n",
    "    \n",
    "    heatmap = np.zeros_like(img[:,:,0])\n",
    "    if file_name!=None:\n",
    "        window_img = np.copy(img)\n",
    "        for box in on_windows:\n",
    "            window_img = cv2.rectangle(window_img,box[0],box[1],(0,0,255),6)\n",
    "        saveImage(window_img, file_name=file_name, file_name_extension='_02_boxed_image', isRGB=True)\n",
    "        heatmap = add_heat(heatmap, on_windows)\n",
    "        heatmap = apply_threshold(heatmap, heatmap_threshold)\n",
    "        if np.max(heatmap)>0:\n",
    "            heatmap *= (int(255/np.max(heatmap)))\n",
    "        saveImage(heatmap, file_name=fname, file_name_extension='_04_heatmap', isRGB=False)\n",
    "        labels = label(heatmap)\n",
    "        labeled_image = draw_labeled_bboxes(np.copy(img), labels)\n",
    "        saveImage(labeled_image, file_name=fname, file_name_extension='_04_labeled_heatmap', isRGB=True)\n",
    "    else:\n",
    "        global global_counter\n",
    "        global round_buffer\n",
    "        buffer_pos = global_counter % round_buffer_size\n",
    "        round_buffer[buffer_pos] = on_windows\n",
    "        for boxes in round_buffer:\n",
    "            heatmap = add_heat(heatmap, boxes)\n",
    "        heatmap = apply_threshold(heatmap, heatmap_threshold)\n",
    "        labels = label(heatmap)\n",
    "        labeled_image = draw_labeled_bboxes(np.copy(img), labels)\n",
    "        global_counter+=1\n",
    "        \n",
    "    return labeled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the test images and produce some output images\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "for fname in images:\n",
    "    labeld_image = detectVehicles(cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB), file_name=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video c:/output_images/project_video.mp4\n",
      "[MoviePy] Writing video c:/output_images/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [26:09<00:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: c:/output_images/project_video.mp4 \n",
      "\n",
      "Wall time: 26min 9s\n"
     ]
    }
   ],
   "source": [
    "# Import MoviePy\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Read the images of the video and write the processed images to a new wideo file\n",
    "video_output = output_folder + 'project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "video_clip = clip1.fl_image(detectVehicles)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
